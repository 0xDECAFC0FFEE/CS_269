{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found gpu: True\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from src import utils, load_data\n",
    "from src.models import lth_maml as lth\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import namedtuple\n",
    "from src import utils\n",
    "\n",
    "print(f\"found gpu: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lottery_ticket_params = {\n",
    "    \"prune_strategy\": {\n",
    "        \"name\": \"early_bird\",\n",
    "        \"rate\": .1,\n",
    "        \"iterations\": 35,\n",
    "    },\n",
    "    \"seeds\": {\n",
    "        \"torch\": 222,\n",
    "        \"cuda\": 222,\n",
    "        \"numpy\": 222\n",
    "    },\n",
    "    \"expr_id\": utils.new_expr_id(\"lth maml\"),\n",
    "    \"model_training_params\": {\n",
    "        \"training_iterations\": 60000, #epoch\n",
    "        \"n_way\": 5,                        # number of classes to choose between for each task\n",
    "        \"k_spt\": 1,                        # k shot for support set (number of examples per class per task)\n",
    "        \"k_qry\": 15,                       # k shot for query set (number of examples per class per task)\n",
    "        \"imgsz\": 84,                       # image size\n",
    "        \"imgc\": 3,                         # this isn't used anywhere????? no idea what it does???? they say its supposed to be 1 or 3...\n",
    "        \"task_num\": 4,                     # meta model batch size\n",
    "        \"meta_lr\": 1e-3,                   # meta model learning rate\n",
    "        \"update_lr\": 0.01,                 # task specific model learning rate\n",
    "        \"update_step\": 5,                  # task specific model training epochs\n",
    "        \"update_step_test\": 10,            # task specific model testing epochs\n",
    "#         \"optimizer\": (\"adam\", {\"lr\": 0.0001}),\n",
    "#         \"loss_func\": \"cross_entropy\",\n",
    "        \"model_name\": \"MAML\",\n",
    "        \"dataset_name\": \"mini_imagenet\",\n",
    "        \"layer_definitions\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "lottery_ticket_params[\"model_training_params\"][\"layer_definitions\"] = [\n",
    "    ('conv2d', [32, 3, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [32, 32, 3, 3, 1, 0]),\n",
    "    ('relu', [True]),\n",
    "    ('bn', [32]),\n",
    "    ('max_pool2d', [2, 1, 0]),\n",
    "    ('flatten', []),\n",
    "    ('linear', [lottery_ticket_params[\"model_training_params\"][\"n_way\"], 32 * 5 * 5]) # 32 * 5 * 5\n",
    "]\n",
    "utils.set_seeds(lottery_ticket_params[\"seeds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :val, b:100, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:84\n"
     ]
    }
   ],
   "source": [
    "args = lottery_ticket_params[\"model_training_params\"]\n",
    "dataset = load_data.mini_imagenet(args)\n",
    "\n",
    "# train, val, test = dataset\n",
    "\n",
    "# images_support, labels_support, images_query, labels_query = next(iter(train))\n",
    "# print(f\"num train batches: {len(train)}\")\n",
    "# print(f\"images_support {images_support.shape}\")\n",
    "# print(f\"labels_support {labels_support.shape}\")\n",
    "# print(f\"images_query {images_query.shape}\")\n",
    "# print(f\"labels_query {labels_query.shape}\")\n",
    "\n",
    "# images = images_query.flatten(0, 1)\n",
    "# labels = labels_query.flatten(0, 1)\n",
    "# for i in range(len({i.numpy().item() for i in labels})):\n",
    "#     grid = torchvision.utils.make_grid(images[labels == i])\n",
    "#     with SummaryWriter(f'tensorboard/lth_maml_miniimagenet') as writer:\n",
    "#         writer.add_image('processed', grid, i)\n",
    "#         writer.flush()\n",
    "\n",
    "# images_support, labels_support, images_query, labels_query = next(iter(val))\n",
    "# print(f\"num val batches: {len(val)}\")\n",
    "# print(f\"images_support {images_support.shape}\")\n",
    "# print(f\"labels_support {labels_support.shape}\")\n",
    "# print(f\"images_query {images_query.shape}\")\n",
    "# print(f\"labels_query {labels_query.shape}\")\n",
    "\n",
    "# images_support, labels_support, images_query, labels_query = next(iter(test))\n",
    "# print(f\"num test batches: {len(test)}\")\n",
    "# print(f\"images_support {images_support.shape}\")\n",
    "# print(f\"labels_support {labels_support.shape}\")\n",
    "# print(f\"images_query {images_query.shape}\")\n",
    "# print(f\"labels_query {labels_query.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0d63568dfdd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# building model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "prune_strategy = lottery_ticket_params[\"prune_strategy\"]\n",
    "training_params = lottery_ticket_params[\"model_training_params\"]\n",
    "prune_rate = prune_strategy[\"rate\"]\n",
    "train_data, val_data, test_data = dataset\n",
    "\n",
    "# building model\n",
    "images, labels = next(iter(train_data))\n",
    "input_shape = images.shape[1:]\n",
    "model = build_model(training_params, input_shape)\n",
    "\n",
    "# saving initial model weights\n",
    "initial_weights = {n: w.cpu().detach() for n, w in model.state_dict().items()}\n",
    "mask = build_mask(model, prune_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting lth run expr 2020-11-05 | 16:18:53 lth maml I4I3T\n",
      "========================\n",
      "starting prune iteration 0\n",
      "========================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d24321c179489fb2a29fe2bfb01052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d48364a3ad4dc5bc9ccd3883db82be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 \ttraining acc: [0.21666667 0.25333333 0.26333333 0.26333333 0.26333333 0.26333333]\n",
      "validating model...\n",
      "val acc: [0.2039 0.2418 0.2422 0.2423 0.2432 0.2427 0.2428 0.243  0.2439 0.2441\n",
      " 0.2451]\n",
      "step: 30 \ttraining acc: [0.14333333 0.24333333 0.24666667 0.25666667 0.26       0.26666667]\n",
      "step: 60 \ttraining acc: [0.20333333 0.28333333 0.29333333 0.29666667 0.29333333 0.29666667]\n",
      "step: 90 \ttraining acc: [0.20666667 0.32666667 0.34       0.34666667 0.34666667 0.34666667]\n",
      "step: 120 \ttraining acc: [0.23333333 0.33       0.34       0.36       0.36       0.36666667]\n",
      "step: 150 \ttraining acc: [0.23       0.28666667 0.29       0.28666667 0.28333333 0.28      ]\n",
      "step: 180 \ttraining acc: [0.21       0.35333333 0.36       0.37       0.37666667 0.38      ]\n",
      "step: 210 \ttraining acc: [0.22       0.37333333 0.38333333 0.37666667 0.37666667 0.37      ]\n",
      "step: 240 \ttraining acc: [0.19       0.31       0.34666667 0.34666667 0.33333333 0.33      ]\n",
      "step: 270 \ttraining acc: [0.21333333 0.34333333 0.37333333 0.39666667 0.4        0.40666667]\n",
      "step: 300 \ttraining acc: [0.18       0.30333333 0.30333333 0.31       0.31       0.32      ]\n",
      "step: 330 \ttraining acc: [0.18       0.34666667 0.39       0.40666667 0.4        0.4       ]\n",
      "step: 360 \ttraining acc: [0.23666667 0.39333333 0.40333333 0.4        0.41       0.42      ]\n",
      "step: 390 \ttraining acc: [0.19666667 0.33333333 0.34       0.34333333 0.35333333 0.37      ]\n",
      "step: 420 \ttraining acc: [0.21333333 0.28       0.28       0.26666667 0.26666667 0.27666667]\n",
      "step: 450 \ttraining acc: [0.21333333 0.34666667 0.37666667 0.39666667 0.41       0.41      ]\n",
      "step: 480 \ttraining acc: [0.25666667 0.31333333 0.34666667 0.36       0.36333333 0.36      ]\n",
      "validating model...\n",
      "val acc: [0.194  0.2942 0.3157 0.3198 0.3247 0.3252 0.327  0.3289 0.33   0.33\n",
      " 0.3306]\n",
      "step: 510 \ttraining acc: [0.14666667 0.24333333 0.29       0.3        0.29666667 0.3       ]\n",
      "step: 540 \ttraining acc: [0.15       0.27333333 0.29666667 0.31666667 0.33       0.32333333]\n",
      "step: 570 \ttraining acc: [0.16       0.32       0.37333333 0.39       0.4        0.39666667]\n",
      "step: 600 \ttraining acc: [0.24333333 0.29666667 0.33666667 0.35666667 0.36333333 0.37      ]\n",
      "step: 630 \ttraining acc: [0.19333333 0.31333333 0.33333333 0.33666667 0.35       0.35666667]\n"
     ]
    }
   ],
   "source": [
    "# print(f\"starting lth run {expr_params['expr_id']}\")\n",
    "# mask = lth.run(dataset, expr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
